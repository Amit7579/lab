PROGRAM 3

import csv
with open("id3.csv")as f:
    csv_file=csv.reader(f)
    data=list(csv_file)
    specific=data[1][: -1]
    general=[["?" for i in range(len(specific))]for i in range(len(specific))]
    for i in data:
        if i[-1]=="yes":
            for j in range(len(specific)):
                if i[j]!=specific[j]:
                    specific[j]="?"
                    general[j][j]="?"
        elif i[-1]=="no":
            for j in range(len(specific)):
                if i[j]!=specific[j]:
                    general[j][j]=specific[j]
                else:
                    general[j][j]="?"
        print("\n step"+str(data.index(i)+1)+"candiadate")
        print(specific)
        print(general)
    gh=[]
    for i in general:
        for j in i:
            if j!="?":
                gh.append(x)
                break
    print(specific)
    print(gh)
                    



PROGRAM 5

import numpy as np
x=np.array(([2,9],[1,5],[3,6]),dtype=float)
y=np.array(([92],[86],[89]),dtype=float)
x=x/np.amax(x,axis=0)
y=y/100
def sigmoid(x):
    return 1/(1+np.exp(-x))
def derivatives_sigmoid(x):
    return x*(1-x)
epoch=7000
lr=0.1
inputlayer_neurons=2
hiddenlayer_neurons=3
output_neurons=1
wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))
bh=np.random.uniform(size=(1,hiddenlayer_neurons))
wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))
bout=np.random.uniform(size=(1,output_neurons))
for i in range(epoch):
 hinp1=np.dot(x,wh)
 hinp=hinp1+bh
 hlayer_act=sigmoid(hinp)
 outinp1=np.dot(hlayer_act,wout)
 outinp=outinp1+bout
 output=sigmoid(outinp)
print("Input:\n"+str(x))
print("Actual output:\n"+str(y))
print("Predicted output:\n",output)


PROGRAM 6

from sklearn.datasets import load_iris
iris=load_iris()
x=iris.data
y=iris.target
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.4,random_state=2)
print('training data',xtrain)
print('training data',ytrain)
print('testing data',xtest)
print('testing data',ytest)
gnb=GaussianNB()
gnb.fit(xtrain,ytrain)
y_pred=gnb.predict(xtest)
from sklearn import metrics
print('accuracy is',metrics.accuracy_score(ytest,y_pred)*100)


PROGRAM 7

import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.cluster import KMeans
import pandas as pd
import numpy as np
import sklearn.metrics as sm
iris=datasets.load_iris()
x=pd.DataFrame(iris.data)
x.columns=['sepal_length','sepal_width','petal_length','petal_width']
y=pd.DataFrame(iris.target)
y.columns=['Targets']
plt.figure(figsize=(14,7))
model=KMeans(n_clusters=3)
model.fit(x)
model.labels_
plt.figure(figsize=(14,7))
colormap=np.array(['red','lime','Black'])
plt.subplot(1,2,1)
plt.scatter(x.petal_length,x.petal_width,c=colormap[y.Targets],s=40)
plt.title('EM clustering')
plt.subplot(1,2,2)
plt.scatter(x.petal_length,x.petal_width,c=colormap[model.labels_],s=40)
plt.title('KMeans clustering')
acc=sm.accuracy_score(y,model.labels_)
print(acc*10)


PROGRAM 8

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report,confusion_matrix
from sklearn import datasets
iris=datasets.load_iris()
iris_data=iris.data
iris_labels=iris.target
print(iris_data)
print(iris_labels)
xtrain,xtest,ytrain,ytest=train_test_split(iris_data,iris_labels,test_size=0.30)
classifier=KNeighborsClassifier(n_neighbors=5)
classifier.fit(x_train,y_train)
y_pred=classifier.predict(x_test)
print('confusion matrix is as follows')
print(confusion_matrix(y_test,y_pred))
print('Accuracy metrices')
print(classification_report(y_test,y_pred))


PROGRAM 9

import numpy as np
import matplotlib.pyplot as plt

def local_regression(x0, X, Y, tau):
    x0 = [1, x0]   
    X = [[1, i] for i in X]
    X = np.asarray(X)
    xw = (X.T) * np.exp(np.sum((X - x0) ** 2, axis=1) / (-2 * tau))
    beta = np.linalg.pinv(xw @ X) @ xw @ Y @ x0  
    return beta    

def draw(tau):
    prediction = [local_regression(x0, X, Y, tau) for x0 in domain]
    plt.plot(X, Y, 'o', color='black')
    plt.plot(domain, prediction, color='red')
    plt.show()

X = np.linspace(-3, 3, num=1000)
domain = X
Y = np.log(np.abs(X ** 2 - 1) + .5)

draw(10)
draw(0.1)
draw(0.01)
draw(0.001)
